import { getFaceValidation } from '@/utils/getFaceValidation';
import { useEffect, useRef, useState } from 'react'

export const useCamera = () => {
    const [isCameraOpen, setIsCameraOpen] = useState(false);
    const [photoDataUrl, setPhotoDataUrl] = useState<string | null>(null);
    const [facingMode, setFacingMode] = useState<'user' | 'environment'>('user');
    const [hasMultipleCameras, setHasMultipleCameras] = useState(true);
    const [faceDetected, setFaceDetected] = useState(false);
    const [facePosition, setFacePosition] = useState<{ x: number, y: number, width: number, height: number } | null>(null);
    const [isProcessingFrame, setIsProcessingFrame] = useState(false);
    const [isValidatingWithEndpoint, setIsValidatingWithEndpoint] = useState(false);
    const [validationAttempts, setValidationAttempts] = useState(0);
    const [maxValidationAttempts] = useState(10);
    const [captureInterval] = useState(3000);
    const [photoFrozen, setPhotoFrozen] = useState(false);

    const videoRef = useRef<HTMLVideoElement | null>(null);
    const canvasRef = useRef<HTMLCanvasElement | null>(null);
    const detectionCanvasRef = useRef<HTMLCanvasElement | null>(null);
    const streamRef = useRef<MediaStream | null>(null);
    const fileInputRef = useRef<HTMLInputElement | null>(null);
    const isTogglingRef = useRef(false);
    const captureIntervalRef = useRef<NodeJS.Timeout | null>(null);
    const endpointUrl = useRef('http://localhost:8000/api/validate-face');
    const streamInitializingRef = useRef(false);

    const checkMultipleCameras = async () => {
        try {
            const devices = await navigator.mediaDevices.enumerateDevices();
            const videoDevices = devices.filter(device => device.kind === 'videoinput');
            setHasMultipleCameras(videoDevices.length > 1);
        } catch (error) {
            console.error('Error al detectar c√°maras:', error);
            setHasMultipleCameras(false);
        }
    };

    const captureFrameForValidation = async () => {
        if (photoFrozen || !videoRef.current || !canvasRef.current || isProcessingFrame) return;

        const video = videoRef.current;
        const canvas = canvasRef.current;

        try {
            const w = video.videoWidth || 640;
            const h = video.videoHeight || 480;
            canvas.width = w;
            canvas.height = h;

            const ctx = canvas.getContext("2d");
            if (!ctx) return;

            ctx.drawImage(video, 0, 0, w, h);
            
            // ‚úÖ MEJORA: Usar calidad m√°xima para validaci√≥n
            const dataUrl = canvas.toDataURL("image/jpeg", 0.95);

            await validateFaceWithEndpoint(dataUrl);
        } catch (error) {
            console.error('Error al capturar frame:', error);
        }
    };

    const validateFaceWithEndpoint = async (imageDataUrl: string) => {
        if (photoFrozen || isValidatingWithEndpoint || validationAttempts >= maxValidationAttempts) return;

        setIsValidatingWithEndpoint(true);
        setValidationAttempts(prev => prev + 1);

        try {
            const result = await getFaceValidation(imageDataUrl);

            if (result.tiene_cara && result.num_caras > 0) {
                setFaceDetected(true);
                setPhotoDataUrl(imageDataUrl);
                setPhotoFrozen(true);

                if (captureIntervalRef.current) {
                    clearInterval(captureIntervalRef.current);
                    captureIntervalRef.current = null;
                }

                if (result.coordenadas && result.coordenadas.length > 0) {
                    const coordenada = result.coordenadas[0];
                    setFacePosition({
                        x: coordenada.x,
                        y: coordenada.y,
                        width: coordenada.ancho || 0,
                        height: coordenada.alto || 0
                    });
                }

                console.log('‚úÖ Rostro v√°lido detectado y guardado');
            } else {
                setFaceDetected(false);
                setFacePosition(null);
                console.log(`‚ùå Intento ${validationAttempts}/${maxValidationAttempts}: ${result.error || 'Rostro no detectado'}`);

                if (validationAttempts >= maxValidationAttempts) {
                    console.log('üîÑ M√°ximo de intentos alcanzado. Deteniendo validaci√≥n autom√°tica.');
                    stopAutomaticCapture();
                }
            }
        } catch (error) {
            console.error('Error al validar rostro con endpoint:', error);
            setFaceDetected(false);
            setFacePosition(null);

            if (validationAttempts >= maxValidationAttempts) {
                stopAutomaticCapture();
            }
        } finally {
            setIsValidatingWithEndpoint(false);
        }
    };

    const startAutomaticCapture = () => {
        if (captureIntervalRef.current || photoFrozen) return;

        console.log(`üé• Iniciando captura autom√°tica cada ${captureInterval}ms`);

        setTimeout(captureFrameForValidation, 1000);
        captureIntervalRef.current = setInterval(captureFrameForValidation, captureInterval);
    };

    const stopAutomaticCapture = () => {
        if (captureIntervalRef.current) {
            clearInterval(captureIntervalRef.current);
            captureIntervalRef.current = null;
            console.log('‚èπÔ∏è Captura autom√°tica detenida');
        }
    };

    const resetValidation = () => {
        setFaceDetected(false);
        setFacePosition(null);
        setValidationAttempts(0);
        setPhotoFrozen(false);
        setIsValidatingWithEndpoint(false);
        stopAutomaticCapture();
    };

    // ‚úÖ CR√çTICO: Funci√≥n mejorada para detener el stream
    const stopStreamSafely = async () => {
        console.log('üõë Deteniendo stream de forma segura...');

        stopAutomaticCapture();

        // Pausar el video
        if (videoRef.current) {
            try {
                videoRef.current.pause();
                // ‚úÖ NUEVO: Limpiar srcObject inmediatamente
                videoRef.current.srcObject = null;
            } catch (error) {
                console.warn('Error al pausar video:', error);
            }
        }

        await new Promise(resolve => setTimeout(resolve, 100));

        // ‚úÖ CR√çTICO: Detener TODOS los tracks del stream
        if (streamRef.current) {
            try {
                const tracks = streamRef.current.getTracks();
                console.log(`üìπ Deteniendo ${tracks.length} tracks...`);
                
                tracks.forEach((track) => {
                    track.stop();
                    console.log(`‚úÖ Track detenido: ${track.kind} - Estado: ${track.readyState}`);
                });
                
                // ‚úÖ NUEVO: Limpiar el stream ref inmediatamente
                streamRef.current = null;
            } catch (error) {
                console.error('‚ùå Error al detener tracks:', error);
            }
        }

        // ‚úÖ NUEVO: Esperar m√°s para liberar recursos en dispositivos lentos
        await new Promise(resolve => setTimeout(resolve, 300));
        
        console.log('‚úÖ Stream completamente detenido');
    };

    const startStreamSafely = async (constraints: MediaStreamConstraints) => {
        if (streamInitializingRef.current) {
            console.warn('‚ö†Ô∏è Stream ya se est√° inicializando, esperando...');
            let attempts = 0;
            while (streamInitializingRef.current && attempts < 30) {
                await new Promise(resolve => setTimeout(resolve, 100));
                attempts++;
            }
            if (streamInitializingRef.current) return null;
        }

        streamInitializingRef.current = true;

        try {
            console.log('üé¨ Iniciando stream con constraints:', constraints);

            if (!videoRef.current) {
                throw new Error('videoRef no disponible antes de getUserMedia');
            }

            const stream = await navigator.mediaDevices.getUserMedia(constraints);

            if (!videoRef.current) {
                console.warn('‚ö†Ô∏è videoRef perdido despu√©s de getUserMedia');
                stream.getTracks().forEach(track => track.stop());
                return null;
            }

            videoRef.current.srcObject = null;
            await new Promise(resolve => setTimeout(resolve, 50));

            videoRef.current.srcObject = stream;
            streamRef.current = stream;

            await new Promise<void>((resolve, reject) => {
                const video = videoRef.current;
                if (!video) {
                    reject(new Error('Video ref perdido'));
                    return;
                }

                if (video.videoWidth > 0 && video.videoHeight > 0) {
                    console.log('‚úÖ Metadatos ya disponibles');
                    resolve();
                    return;
                }

                const handleLoadedMetadata = () => {
                    console.log('‚úÖ Metadatos cargados:', {
                        width: video.videoWidth,
                        height: video.videoHeight
                    });
                    cleanup();
                    resolve();
                };

                const handleError = (error: Event) => {
                    console.error('‚ùå Error al cargar metadatos:', error);
                    cleanup();
                    reject(error);
                };

                const cleanup = () => {
                    video.removeEventListener('loadedmetadata', handleLoadedMetadata);
                    video.removeEventListener('error', handleError);
                    if (timeoutId) clearTimeout(timeoutId);
                };

                video.addEventListener('loadedmetadata', handleLoadedMetadata);
                video.addEventListener('error', handleError);

                const timeoutId = setTimeout(() => {
                    cleanup();
                    reject(new Error('Timeout esperando metadatos'));
                }, 8000);
            });

            try {
                videoRef.current.muted = true;
                videoRef.current.playsInline = true;

                await videoRef.current.play();
                console.log('‚ñ∂Ô∏è Video reproduci√©ndose');

                await new Promise(resolve => setTimeout(resolve, 100));

                if (videoRef.current.paused) {
                    console.warn('‚ö†Ô∏è Video sigue pausado, reintentando...');
                    await videoRef.current.play();
                }

            } catch (playError) {
                console.error('‚ùå Error al reproducir video:', playError);
                throw new Error('No se pudo reproducir el video');
            }

            return stream;

        } catch (error) {
            console.error('‚ùå Error al iniciar stream:', error);
            throw error;
        } finally {
            streamInitializingRef.current = false;
        }
    };

    const openCamera = async () => {
        try {
            if (!navigator.mediaDevices?.getUserMedia) {
                fileInputRef.current?.click();
                return;
            }
    
            await stopStreamSafely();
            resetValidation();
    
            await checkMultipleCameras();
    
            await new Promise(resolve => setTimeout(resolve, 200));
    
            setIsCameraOpen(true);
    
            await new Promise(resolve => setTimeout(resolve, 300));
    
            if (!videoRef.current) {
                console.error('‚ùå videoRef no disponible despu√©s de abrir c√°mara');
                throw new Error('Video element no montado');
            }
    
            // ‚úÖ MEJORA: Constraints optimizados para mejor calidad
            const constraints = {
                video: {
                    facingMode: { ideal: facingMode },
                    width: { ideal: 1920, max: 3840 },  // Aumentado
                    height: { ideal: 1080, max: 2160 }, // Aumentado
                    aspectRatio: { ideal: 16 / 9 },
                    frameRate: { ideal: 30, max: 60 }   // A√±adido
                },
                audio: false,
            };
    
            const stream = await startStreamSafely(constraints);
    
            if (!stream) {
                throw new Error('No se pudo obtener el stream');
            }
    
            setTimeout(startAutomaticCapture, 1000);
    
        } catch (error) {
            console.error('Error al abrir c√°mara:', error);
            setIsCameraOpen(false);
            await stopStreamSafely();
    
            setTimeout(() => {
                fileInputRef.current?.click();
            }, 100);
        }
    };

    // ‚úÖ CR√çTICO: closeCamera mejorado
    const closeCamera = async () => {
        console.log('üö™ Cerrando c√°mara...');
        
        // Primero detenemos todo el procesamiento
        stopAutomaticCapture();
        
        // Luego detenemos el stream
        await stopStreamSafely();
        
        // Finalmente actualizamos el estado
        setIsCameraOpen(false);
        resetValidation();
        isTogglingRef.current = false;
        
        console.log('‚úÖ C√°mara cerrada completamente');
    };

    const toggleCamera = async () => {
        if (!hasMultipleCameras || isTogglingRef.current || streamInitializingRef.current) {
            console.warn('‚ö†Ô∏è No se puede cambiar c√°mara en este momento');
            return;
        }

        isTogglingRef.current = true;
        const newMode = facingMode === 'user' ? 'environment' : 'user';

        try {
            console.log(`üîÑ Cambiando de ${facingMode} a ${newMode}`);

            await stopStreamSafely();

            await new Promise(resolve => setTimeout(resolve, 800));

            // ‚úÖ MEJORA: Constraints mejorados para toggle
            const constraintStrategies = [
                {
                    video: {
                        facingMode: { exact: newMode },
                        width: { ideal: 1920, max: 3840 },
                        height: { ideal: 1080, max: 2160 },
                        aspectRatio: { ideal: 16 / 9 },
                        frameRate: { ideal: 30 }
                    },
                    audio: false,
                },
                {
                    video: {
                        facingMode: { ideal: newMode },
                        width: { ideal: 1280, max: 1920 },
                        height: { ideal: 720, max: 1080 }
                    },
                    audio: false,
                },
                {
                    video: { facingMode: newMode },
                    audio: false,
                }
            ];

            let streamObtained = false;

            for (let i = 0; i < constraintStrategies.length && !streamObtained; i++) {
                try {
                    console.log(`üìã Intentando estrategia ${i + 1}...`);

                    const stream = await startStreamSafely(constraintStrategies[i]);

                    if (stream) {
                        setFacingMode(newMode);
                        streamObtained = true;
                        resetValidation();
                        setTimeout(startAutomaticCapture, 1000);
                        console.log(`‚úÖ Estrategia ${i + 1} exitosa`);
                    }

                } catch (strategyError) {
                    console.log(`‚ùå Estrategia ${i + 1} fall√≥:`, strategyError);
                    await stopStreamSafely();

                    if (i === constraintStrategies.length - 1) {
                        throw strategyError;
                    }

                    await new Promise(resolve => setTimeout(resolve, 500));
                }
            }

        } catch (error) {
            console.error('‚ùå Error al cambiar c√°mara:', error);
            await stopStreamSafely();
            setFacingMode(facingMode === 'user' ? 'environment' : 'user');
            
            try {
                const fallbackConstraints = {
                    video: { facingMode: facingMode },
                    audio: false
                };
                await startStreamSafely(fallbackConstraints);
            } catch (fallbackError) {
                console.error('‚ùå Error en fallback:', fallbackError);
                await closeCamera();
            }
        } finally {
            isTogglingRef.current = false;
        }
    };

    // ‚úÖ CR√çTICO: capturePhoto mejorado - CIERRA LA C√ÅMARA
    const capturePhoto = async () => {
        if (!faceDetected || !photoDataUrl) {
            console.log('No hay rostro v√°lido detectado para guardar');
            return;
        }

        console.log('üì∏ Guardando foto y cerrando c√°mara...');
        
        // ‚úÖ CR√çTICO: Capturar foto de alta calidad antes de cerrar
        if (videoRef.current && canvasRef.current) {
            const video = videoRef.current;
            const canvas = canvasRef.current;
            
            const w = video.videoWidth || 1920;
            const h = video.videoHeight || 1080;
            canvas.width = w;
            canvas.height = h;

            const ctx = canvas.getContext("2d");
            if (ctx) {
                ctx.drawImage(video, 0, 0, w, h);
                // ‚úÖ MEJORA: Calidad m√°xima 0.98
                const highQualityPhoto = canvas.toDataURL("image/jpeg", 0.98);
                setPhotoDataUrl(highQualityPhoto);
                console.log('‚úÖ Foto de alta calidad capturada');
            }
        }
        
        // ‚úÖ CR√çTICO: Cerrar la c√°mara completamente
        await closeCamera();
        
        console.log('‚úÖ Foto guardada y c√°mara cerrada');
    };

    const onFileCapture = (e: React.ChangeEvent<HTMLInputElement>) => {
        const file = e.target.files?.[0];
        if (!file) return;
        const reader = new FileReader();
        reader.onload = () => setPhotoDataUrl(reader.result as string);
        reader.readAsDataURL(file);
    };

    const setEndpointUrl = (url: string) => {
        endpointUrl.current = url;
    };

    // ‚úÖ CR√çTICO: Cleanup al desmontar componente
    useEffect(() => {
        checkMultipleCameras();

        return () => {
            console.log('üßπ Limpiando recursos al desmontar...');
            stopAutomaticCapture();
            
            if (streamRef.current) {
                streamRef.current.getTracks().forEach((track) => {
                    track.stop();
                    console.log('‚úÖ Track detenido en cleanup:', track.kind);
                });
                streamRef.current = null;
            }
            
            if (videoRef.current) {
                videoRef.current.srcObject = null;
            }
        };
    }, []);

    return {
        isCameraOpen,
        photoDataUrl,
        setPhotoDataUrl,
        facingMode,
        hasMultipleCameras,
        faceDetected,
        facePosition,
        isValidatingWithEndpoint,
        validationAttempts,
        maxValidationAttempts,
        photoFrozen,
        videoRef,
        canvasRef,
        detectionCanvasRef,
        fileInputRef,
        openCamera,
        closeCamera,
        capturePhoto,
        onFileCapture,
        toggleCamera,
        resetValidation,
        setEndpointUrl
    }
}